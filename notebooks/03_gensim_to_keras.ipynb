{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Keras Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In the last flow, we need to deploy the model to Sagemaker. However, SageMaker is easier to use with one of the pre-defined model types - in this case Tensorflow. \n",
    "\n",
    "In fact, our deployment strategy for the KNN-based model we trained is to first \"export\" it to a TF-Recs model with keras (the function keras_model), and then deploy it to SageMaker with their TensorFlowModel abstraction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "First we import the packages we need and define some config variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for _ in range(3):\n",
    "    if os.path.exists(f'{os.getcwd()}/setup.py'):\n",
    "        break\n",
    "    os.chdir('..')\n",
    "print('Current working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tarfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from src.utils.logging import bprint\n",
    "from src.utils.meta import get_latest_successful_run\n",
    "from src.utils.styling import apply_styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = apply_styling()\n",
    "palette = colors['palette']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Let's retrieved the artifacts from the latest successful run. \n",
    "The `get_latest_successful_run` uses the `metaflow.Flow` object to get results of runs using the (class) name of the flows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOW_NAME = 'ModelingFlow'\n",
    "latest_run = get_latest_successful_run(FLOW_NAME)\n",
    "final_vectors = latest_run.data.final_vectors\n",
    "final_dataset = latest_run.data.final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(latest_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Retrieval Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "First, we gather the ids and the embeddings of the songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_ids = np.array(final_vectors.index_to_key)\n",
    "songs_embeddings = np.array([final_vectors[idx] for idx in songs_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "We need to include an \"unknown\" item in the embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = len(songs_embeddings)\n",
    "embedding_size = songs_embeddings[0].shape[0]\n",
    "bprint(f'Num of embeddings: {len(songs_embeddings):,}', level=3)\n",
    "bprint(f'Embeddings dimensions: {embedding_size}', level=3)\n",
    "\n",
    "bprint('Adding a vector for unknown items', level=3)\n",
    "unknown_vector = np.zeros((1, embedding_size))\n",
    "embedding_matrix = np.vstack([unknown_vector, songs_embeddings])\n",
    "bprint('First item:', embedding_matrix[0][0:5], level=4)\n",
    "bprint('Shape of the matrix:', embedding_matrix.shape, level=4)\n",
    "assert embedding_matrix[0][0] == 0.0\n",
    "\n",
    "bprint('Initializing layers and network', level=3)\n",
    "lookup_layer = tf.keras.layers.StringLookup(vocabulary=songs_ids, mask_token=None)\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=embedding_matrix.shape[0],\n",
    "    output_dim=embedding_matrix.shape[1],\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=False,\n",
    ")\n",
    "embedding_layer.build((None,))\n",
    "\n",
    "model = tf.keras.Sequential([lookup_layer, embedding_layer])\n",
    "\n",
    "bprint('Creating retrieval model', level=3)\n",
    "brute_force = tfrs.layers.factorized_top_k.BruteForce(model)\n",
    "song_index = brute_force.index(candidates=songs_embeddings, identifiers=songs_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Finally, we test the model with one of the songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(song_id, k=10):\n",
    "    \"\"\"\n",
    "    Get recommendations for a given song.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    song_id : int\n",
    "        The ID of the song for which recommendations are to be generated.\n",
    "    k : int, optional\n",
    "        The number of recommendations to be returned. Default is 10.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing the song vector, recommendation scores, and recommendation IDs.\n",
    "        - song_vector : numpy.ndarray\n",
    "            The vector representation of the input song.\n",
    "        - rec_scores : numpy.ndarray\n",
    "            The scores of the recommended songs.\n",
    "        - rec_ids : numpy.ndarray\n",
    "            The IDs of the recommended songs.\n",
    "    \"\"\"\n",
    "    song_vector = model(np.array([song_id]))\n",
    "    rec_scores, rec_ids = song_index(tf.constant([song_id]), k=k)\n",
    "    return song_vector, rec_scores, rec_ids\n",
    "\n",
    "def pprint_recommendations(song_id, k=10):\n",
    "    \"\"\"\n",
    "    Print recommendations for a given song.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    song_id : int\n",
    "        The ID of the song for which recommendations are to be generated.\n",
    "    k : int, optional\n",
    "        The number of recommendations to be returned. Default is 10.\n",
    "    \"\"\"\n",
    "    song_vector, rec_scores, rec_ids = get_recommendations(song_id, k=k)\n",
    "    bprint('Song ID:', song_id, level=4, prefix='*')\n",
    "    bprint('Song vector:', song_vector.numpy()[0][:5], level=4)\n",
    "    bprint('Recommendations after track:', level=4)\n",
    "    for score, song_id in zip(rec_scores[0].numpy(), rec_ids[0].numpy()):\n",
    "        song_id = str(song_id, 'utf-8')\n",
    "        if not song_id == song_id:\n",
    "            continue\n",
    "        bprint(f'{score:.2f} - {song_id}', level=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(get_recommendations('Alabimbombao~', k=5)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "bprint('Testing retrieval model', level=3)\n",
    "test_id = 'Alabimbombao~'  # Unknown!\n",
    "pprint_recommendations(test_id, k=5)\n",
    "\n",
    "test_index = 3\n",
    "test_id = songs_ids[test_index]\n",
    "pprint_recommendations(test_id, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Let's put it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retrieval_model(songs_ids, songs_embeddings):\n",
    "    embedding_size = songs_embeddings[0].shape[0]\n",
    "    bprint(f'Num of embeddings: {len(songs_embeddings):,}', level=3)\n",
    "    bprint(f'Embeddings dimensions: {embedding_size}', level=3)\n",
    "\n",
    "    bprint('Adding a vector for unknown items', level=3)\n",
    "    unknown_vector = np.zeros((1, embedding_size))\n",
    "    embedding_matrix = np.vstack([unknown_vector, songs_embeddings])\n",
    "    bprint('First item:', embedding_matrix[0][0:5], level=4)\n",
    "    bprint('Shape of the matrix:', embedding_matrix.shape, level=4)\n",
    "    assert embedding_matrix[0][0] == 0.0\n",
    "\n",
    "    bprint('Initializing layers and network', level=3)\n",
    "    lookup_layer = tf.keras.layers.StringLookup(vocabulary=songs_ids, mask_token=None)\n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        input_dim=embedding_matrix.shape[0],\n",
    "        output_dim=embedding_matrix.shape[1],\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=False,\n",
    "    )\n",
    "    embedding_layer.build((None,))\n",
    "\n",
    "    model = tf.keras.Sequential([lookup_layer, embedding_layer])\n",
    "\n",
    "    bprint('Creating retrieval model', level=3)\n",
    "    brute_force = tfrs.layers.factorized_top_k.BruteForce(model)\n",
    "    song_index = brute_force.index(candidates=songs_embeddings, identifiers=songs_ids)\n",
    "    return model, song_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalModel:\n",
    "    \"\"\"\n",
    "    Build a retrieval model using TF recommender abstraction by packaging\n",
    "    the vector space in a Keras object.\n",
    "\n",
    "    We can ship the artifact \"as is\" to a Sagemaker endpoint, and\n",
    "    benefit from the PaaS abstraction and hardware acceleration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, songs_ids: np.ndarray, songs_embeddings: np.ndarray):\n",
    "        \"\"\"Initialize the retrieval model.\"\"\"\n",
    "        bprint('Building retrieval model', level=2)\n",
    "        model, song_index = build_retrieval_model(songs_ids, songs_embeddings)\n",
    "        self.model = model\n",
    "        self.song_index = song_index\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"Test the retrieval model.\"\"\"\n",
    "        bprint('Testing retrieval model', level=2)\n",
    "        test_index = random.randint(0, 10)\n",
    "        test_id = songs_ids[test_index]\n",
    "        self.pprint_recommendations(test_id, k=5)\n",
    "        test_id = r'Alabimbombao ヽ(≧◡≦)八(o^ ^o)ノ'  # Unknown!\n",
    "        self.pprint_recommendations(test_id, k=5)\n",
    "\n",
    "    def get_recommendations(self, song_id: str, k: int = 10) -> Tuple:\n",
    "        \"\"\"\n",
    "        Get recommendations for a given song.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        song_id : int\n",
    "            The ID of the song for which recommendations are to be generated.\n",
    "        k : int, optional\n",
    "            The number of recommendations to be returned. Default is 10.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing the song vector, recommendation scores, and recommendation IDs.\n",
    "            - song_vector : Tensorflow Tensor\n",
    "                The vector representation of the input song.\n",
    "            - rec_scores : Tensorflow Tensor\n",
    "                The scores of the recommended songs.\n",
    "            - rec_ids : Tensorflow Tensor\n",
    "                The IDs of the recommended songs.\n",
    "        \"\"\"\n",
    "        song_vector = self.model(np.array([song_id]))\n",
    "        rec_scores, rec_ids = self.song_index(tf.constant([song_id]), k=k)\n",
    "        return song_vector, rec_scores, rec_ids\n",
    "\n",
    "    def pprint_recommendations(self, song_id, k=10):\n",
    "        \"\"\"\n",
    "        Print recommendations for a given song.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        song_id : int\n",
    "            The ID of the song for which recommendations are to be generated.\n",
    "        k : int, optional\n",
    "            The number of recommendations to be returned. Default is 10.\n",
    "        \"\"\"\n",
    "        song_vector, rec_scores, rec_ids = self.get_recommendations(song_id, k=k)\n",
    "        bprint('Song ID:', song_id, level=3, prefix='* ')\n",
    "        bprint('Song vector:', song_vector.numpy()[0][:5], level=3)\n",
    "        bprint('Recommendations after track:', level=3)\n",
    "        for rec_score, rec_id in zip(rec_scores[0].numpy(), rec_ids[0].numpy()):\n",
    "            rec_id = str(rec_id, 'utf-8')\n",
    "            if rec_id != song_id:\n",
    "                bprint(f'{rec_score:.2f} - {rec_id}', level=4)\n",
    "\n",
    "    def save(self, *args, **kwargs):\n",
    "        \"\"\"Save the retrieval model.\"\"\"\n",
    "        self.song_index.save(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_ids = np.array(final_vectors.index_to_key)\n",
    "songs_embeddings = np.array([final_vectors[idx] for idx in songs_ids])\n",
    "\n",
    "model = RetrievalModel(songs_ids, songs_embeddings)\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "bprint('Saving model locally', level=2)\n",
    "model_timestamp = int(round(time.time() * 1000))\n",
    "models_dir = Path('data/04_models')\n",
    "model_name = models_dir / f'playlist-recs-model-{model_timestamp}/1'\n",
    "local_tar_name = models_dir / f'model-{model_timestamp}.tar.gz'\n",
    "bprint(f'Model path: {model_name}', level=3)\n",
    "bprint(f'Tarfile path: {local_tar_name}', level=3)\n",
    "\n",
    "model.save(filepath=str(model_name))  # Save the tfrs index model\n",
    "with tarfile.open(local_tar_name, mode='w:gz') as _tar:\n",
    "    _tar.add(model_name, recursive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
